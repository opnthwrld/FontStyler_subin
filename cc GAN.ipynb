{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convolutional conditional GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyreadr as py # library to read .Rdata files in python\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from time import time\n",
    "import pickle\n",
    "import datetime\n",
    "import random\n",
    "import math\n",
    "import csv\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix,confusion_matrix,classification_report\n",
    "from sklearn.preprocessing import StandardScaler,Normalizer\n",
    "from sklearn.model_selection import RandomizedSearchCV,GridSearchCV,KFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score,f1_score,log_loss,recall_score,classification_report\n",
    "from sklearn.preprocessing import scale, robust_scale, minmax_scale, maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataset import Dataset  \n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.model import AE_base\n",
    "from src.data.common.dataset import FontDataset, PickledImageProvider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "validation_split = .15\n",
    "test_split = .05\n",
    "shuffle_dataset = True\n",
    "random_seed = 42\n",
    "\n",
    "lr = 0.0001\n",
    "\n",
    "log_interval = 10\n",
    "epochs = 200\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.function import conv2d, deconv2d, batch_norm, lrelu, dropout\n",
    "from src.data.common.dataset import NewFontDataset, PickledImageProvider, KoreanFontDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 1000 examples\n",
      "processed 2000 examples\n",
      "processed 3000 examples\n",
      "processed 4000 examples\n",
      "processed 5000 examples\n",
      "processed 6000 examples\n",
      "processed 7000 examples\n",
      "processed 8000 examples\n",
      "processed 9000 examples\n",
      "processed 10000 examples\n",
      "processed 11000 examples\n",
      "processed 12000 examples\n",
      "processed 13000 examples\n",
      "processed 14000 examples\n",
      "processed 15000 examples\n",
      "processed 16000 examples\n",
      "processed 17000 examples\n",
      "processed 18000 examples\n",
      "processed 19000 examples\n",
      "processed 20000 examples\n",
      "processed 21000 examples\n",
      "processed 22000 examples\n",
      "processed 23000 examples\n",
      "processed 24000 examples\n",
      "processed 25000 examples\n",
      "processed 26000 examples\n",
      "processed 27000 examples\n",
      "processed 28000 examples\n",
      "processed 29000 examples\n",
      "processed 30000 examples\n",
      "processed 31000 examples\n",
      "processed 32000 examples\n",
      "processed 33000 examples\n",
      "processed 34000 examples\n",
      "processed 35000 examples\n",
      "processed 36000 examples\n",
      "processed 37000 examples\n",
      "processed 38000 examples\n",
      "processed 39000 examples\n",
      "processed 40000 examples\n",
      "processed 41000 examples\n",
      "processed 42000 examples\n",
      "processed 43000 examples\n",
      "processed 44000 examples\n",
      "processed 45000 examples\n",
      "processed 46000 examples\n",
      "processed 47000 examples\n",
      "processed 48000 examples\n",
      "processed 49000 examples\n",
      "processed 50000 examples\n",
      "processed 51000 examples\n",
      "processed 52000 examples\n",
      "processed 53000 examples\n",
      "processed 54000 examples\n",
      "processed 55000 examples\n",
      "processed 56000 examples\n",
      "processed 57000 examples\n",
      "processed 58000 examples\n",
      "processed 59000 examples\n",
      "processed 60000 examples\n",
      "processed 61000 examples\n",
      "processed 62000 examples\n",
      "processed 63000 examples\n",
      "processed 64000 examples\n",
      "processed 65000 examples\n",
      "processed 66000 examples\n",
      "processed 67000 examples\n",
      "processed 68000 examples\n",
      "processed 69000 examples\n",
      "processed 70000 examples\n",
      "processed 71000 examples\n",
      "processed 72000 examples\n",
      "processed 73000 examples\n",
      "processed 74000 examples\n",
      "processed 75000 examples\n",
      "processed 76000 examples\n",
      "processed 77000 examples\n",
      "processed 78000 examples\n",
      "processed 79000 examples\n",
      "processed 80000 examples\n",
      "processed 81000 examples\n",
      "processed 82000 examples\n",
      "processed 83000 examples\n",
      "processed 84000 examples\n",
      "processed 85000 examples\n",
      "processed 86000 examples\n",
      "processed 87000 examples\n",
      "processed 88000 examples\n",
      "processed 89000 examples\n",
      "processed 90000 examples\n",
      "processed 91000 examples\n",
      "processed 92000 examples\n",
      "processed 93000 examples\n",
      "processed 94000 examples\n",
      "processed 95000 examples\n",
      "processed 96000 examples\n",
      "processed 97000 examples\n",
      "processed 98000 examples\n",
      "processed 99000 examples\n",
      "processed 100000 examples\n",
      "processed 101000 examples\n",
      "processed 102000 examples\n",
      "processed 103000 examples\n",
      "processed 104000 examples\n",
      "processed 105000 examples\n",
      "processed 106000 examples\n",
      "processed 107000 examples\n",
      "processed 108000 examples\n",
      "processed 109000 examples\n",
      "processed 110000 examples\n",
      "processed 111000 examples\n",
      "processed 112000 examples\n",
      "processed 113000 examples\n",
      "processed 114000 examples\n",
      "processed 115000 examples\n",
      "processed 116000 examples\n",
      "processed 117000 examples\n",
      "processed 118000 examples\n",
      "processed 119000 examples\n",
      "processed 120000 examples\n",
      "processed 121000 examples\n",
      "processed 122000 examples\n",
      "processed 123000 examples\n",
      "processed 124000 examples\n",
      "processed 125000 examples\n",
      "processed 126000 examples\n",
      "processed 127000 examples\n",
      "processed 128000 examples\n",
      "processed 129000 examples\n",
      "processed 130000 examples\n",
      "processed 131000 examples\n",
      "processed 132000 examples\n",
      "processed 133000 examples\n",
      "processed 134000 examples\n",
      "processed 135000 examples\n",
      "processed 136000 examples\n",
      "processed 137000 examples\n",
      "processed 138000 examples\n",
      "processed 139000 examples\n",
      "processed 140000 examples\n",
      "processed 141000 examples\n",
      "processed 142000 examples\n",
      "processed 143000 examples\n",
      "processed 144000 examples\n",
      "processed 145000 examples\n",
      "processed 146000 examples\n",
      "processed 147000 examples\n",
      "processed 148000 examples\n",
      "processed 149000 examples\n",
      "processed 150000 examples\n",
      "processed 151000 examples\n",
      "processed 152000 examples\n",
      "processed 153000 examples\n",
      "processed 154000 examples\n",
      "processed 155000 examples\n",
      "processed 156000 examples\n",
      "processed 157000 examples\n",
      "processed 158000 examples\n",
      "processed 159000 examples\n",
      "processed 160000 examples\n",
      "processed 161000 examples\n",
      "processed 162000 examples\n",
      "processed 163000 examples\n",
      "processed 164000 examples\n",
      "processed 165000 examples\n",
      "processed 166000 examples\n",
      "processed 167000 examples\n",
      "processed 168000 examples\n",
      "processed 169000 examples\n",
      "processed 170000 examples\n",
      "processed 171000 examples\n",
      "processed 172000 examples\n",
      "processed 173000 examples\n",
      "processed 174000 examples\n",
      "processed 175000 examples\n",
      "processed 176000 examples\n",
      "processed 177000 examples\n",
      "processed 178000 examples\n",
      "processed 179000 examples\n",
      "processed 180000 examples\n",
      "processed 181000 examples\n",
      "processed 182000 examples\n",
      "processed 183000 examples\n",
      "processed 184000 examples\n",
      "processed 185000 examples\n",
      "processed 186000 examples\n",
      "processed 187000 examples\n",
      "processed 188000 examples\n",
      "processed 189000 examples\n",
      "processed 190000 examples\n",
      "processed 191000 examples\n",
      "processed 192000 examples\n",
      "processed 193000 examples\n",
      "processed 194000 examples\n",
      "processed 195000 examples\n",
      "processed 196000 examples\n",
      "processed 197000 examples\n",
      "processed 198000 examples\n",
      "processed 199000 examples\n",
      "processed 200000 examples\n",
      "processed 201000 examples\n",
      "processed 202000 examples\n",
      "processed 203000 examples\n",
      "processed 204000 examples\n",
      "processed 205000 examples\n",
      "processed 206000 examples\n",
      "processed 207000 examples\n",
      "processed 208000 examples\n",
      "processed 209000 examples\n",
      "processed 210000 examples\n",
      "processed 211000 examples\n",
      "processed 212000 examples\n",
      "processed 213000 examples\n",
      "processed 214000 examples\n",
      "processed 215000 examples\n",
      "processed 216000 examples\n",
      "processed 217000 examples\n",
      "processed 218000 examples\n",
      "processed 219000 examples\n",
      "processed 220000 examples\n",
      "processed 221000 examples\n",
      "processed 222000 examples\n",
      "processed 223000 examples\n",
      "processed 224000 examples\n",
      "processed 225000 examples\n",
      "processed 226000 examples\n",
      "processed 227000 examples\n",
      "processed 228000 examples\n",
      "processed 229000 examples\n",
      "processed 230000 examples\n",
      "processed 231000 examples\n",
      "processed 232000 examples\n",
      "processed 233000 examples\n",
      "processed 234000 examples\n",
      "processed 235000 examples\n",
      "processed 236000 examples\n",
      "processed 237000 examples\n",
      "processed 238000 examples\n",
      "processed 239000 examples\n",
      "processed 240000 examples\n",
      "processed 241000 examples\n",
      "processed 242000 examples\n",
      "processed 243000 examples\n",
      "processed 244000 examples\n",
      "processed 245000 examples\n",
      "processed 246000 examples\n",
      "processed 247000 examples\n",
      "processed 248000 examples\n",
      "processed 249000 examples\n",
      "processed 250000 examples\n",
      "processed 251000 examples\n",
      "processed 252000 examples\n",
      "processed 253000 examples\n",
      "processed 254000 examples\n",
      "processed 255000 examples\n",
      "processed 256000 examples\n",
      "processed 257000 examples\n",
      "processed 258000 examples\n",
      "processed 259000 examples\n",
      "processed 260000 examples\n",
      "processed 261000 examples\n",
      "processed 262000 examples\n",
      "processed 263000 examples\n",
      "processed 264000 examples\n",
      "processed 265000 examples\n",
      "processed 266000 examples\n",
      "processed 267000 examples\n",
      "processed 268000 examples\n",
      "processed 269000 examples\n",
      "processed 270000 examples\n",
      "processed 271000 examples\n",
      "processed 272000 examples\n",
      "processed 273000 examples\n",
      "processed 274000 examples\n",
      "processed 275000 examples\n",
      "processed 276000 examples\n",
      "processed 277000 examples\n",
      "processed 278000 examples\n",
      "processed 279000 examples\n",
      "processed 280000 examples\n",
      "processed 281000 examples\n",
      "processed 282000 examples\n",
      "processed 283000 examples\n",
      "processed 284000 examples\n",
      "processed 285000 examples\n",
      "processed 286000 examples\n",
      "processed 287000 examples\n",
      "processed 288000 examples\n",
      "processed 289000 examples\n",
      "processed 290000 examples\n",
      "processed 291000 examples\n",
      "processed 292000 examples\n",
      "processed 293000 examples\n",
      "processed 294000 examples\n",
      "processed 295000 examples\n",
      "processed 296000 examples\n",
      "processed 297000 examples\n",
      "processed 298000 examples\n",
      "processed 299000 examples\n",
      "processed 300000 examples\n",
      "processed 301000 examples\n",
      "processed 302000 examples\n",
      "processed 303000 examples\n",
      "processed 304000 examples\n",
      "processed 305000 examples\n",
      "processed 306000 examples\n",
      "processed 307000 examples\n",
      "processed 308000 examples\n",
      "processed 309000 examples\n",
      "processed 310000 examples\n",
      "processed 311000 examples\n",
      "processed 312000 examples\n",
      "processed 313000 examples\n",
      "processed 314000 examples\n",
      "processed 315000 examples\n",
      "processed 316000 examples\n",
      "processed 317000 examples\n",
      "processed 318000 examples\n",
      "processed 319000 examples\n",
      "processed 320000 examples\n",
      "processed 321000 examples\n",
      "processed 322000 examples\n",
      "processed 323000 examples\n",
      "processed 324000 examples\n",
      "processed 325000 examples\n",
      "processed 326000 examples\n",
      "processed 327000 examples\n",
      "processed 328000 examples\n",
      "processed 329000 examples\n",
      "processed 330000 examples\n",
      "processed 331000 examples\n",
      "processed 332000 examples\n",
      "processed 333000 examples\n",
      "processed 334000 examples\n",
      "processed 335000 examples\n",
      "processed 336000 examples\n",
      "processed 337000 examples\n",
      "processed 338000 examples\n",
      "processed 339000 examples\n",
      "processed 340000 examples\n",
      "processed 341000 examples\n",
      "processed 342000 examples\n",
      "processed 343000 examples\n",
      "processed 344000 examples\n",
      "processed 345000 examples\n",
      "processed 346000 examples\n",
      "processed 347000 examples\n",
      "processed 348000 examples\n",
      "processed 349000 examples\n",
      "processed 350000 examples\n",
      "processed 351000 examples\n",
      "processed 352000 examples\n",
      "processed 353000 examples\n",
      "processed 354000 examples\n",
      "processed 355000 examples\n",
      "processed 356000 examples\n",
      "processed 357000 examples\n",
      "processed 358000 examples\n",
      "processed 359000 examples\n",
      "processed 360000 examples\n",
      "processed 361000 examples\n",
      "processed 362000 examples\n",
      "processed 363000 examples\n",
      "processed 364000 examples\n",
      "processed 365000 examples\n",
      "processed 366000 examples\n",
      "processed 367000 examples\n",
      "processed 368000 examples\n",
      "processed 369000 examples\n",
      "processed 370000 examples\n",
      "processed 371000 examples\n",
      "processed 372000 examples\n",
      "processed 373000 examples\n",
      "processed 374000 examples\n",
      "processed 375000 examples\n",
      "processed 376000 examples\n",
      "processed 377000 examples\n",
      "processed 378000 examples\n",
      "processed 379000 examples\n",
      "processed 380000 examples\n",
      "processed 381000 examples\n",
      "processed 382000 examples\n",
      "processed 383000 examples\n",
      "processed 384000 examples\n",
      "processed 385000 examples\n",
      "processed 386000 examples\n",
      "processed 387000 examples\n",
      "processed 388000 examples\n",
      "processed 389000 examples\n",
      "processed 390000 examples\n",
      "processed 391000 examples\n",
      "processed 392000 examples\n",
      "processed 393000 examples\n",
      "processed 394000 examples\n",
      "processed 395000 examples\n",
      "processed 396000 examples\n",
      "processed 397000 examples\n",
      "processed 398000 examples\n",
      "processed 399000 examples\n",
      "processed 400000 examples\n",
      "processed 401000 examples\n",
      "processed 402000 examples\n",
      "processed 403000 examples\n",
      "processed 404000 examples\n",
      "processed 405000 examples\n",
      "processed 406000 examples\n",
      "processed 407000 examples\n",
      "processed 408000 examples\n",
      "processed 409000 examples\n",
      "processed 410000 examples\n",
      "processed 411000 examples\n",
      "processed 412000 examples\n",
      "processed 413000 examples\n",
      "processed 414000 examples\n",
      "processed 415000 examples\n",
      "processed 416000 examples\n",
      "processed 417000 examples\n",
      "processed 418000 examples\n",
      "processed 419000 examples\n",
      "processed 420000 examples\n",
      "processed 421000 examples\n",
      "processed 422000 examples\n",
      "processed 423000 examples\n",
      "processed 424000 examples\n",
      "processed 425000 examples\n",
      "processed 426000 examples\n",
      "processed 427000 examples\n",
      "processed 428000 examples\n",
      "processed 429000 examples\n",
      "processed 430000 examples\n",
      "processed 431000 examples\n",
      "processed 432000 examples\n",
      "processed 433000 examples\n",
      "processed 434000 examples\n",
      "processed 435000 examples\n",
      "processed 436000 examples\n",
      "processed 437000 examples\n",
      "processed 438000 examples\n",
      "processed 439000 examples\n",
      "processed 440000 examples\n",
      "processed 441000 examples\n",
      "processed 442000 examples\n",
      "processed 443000 examples\n",
      "processed 444000 examples\n",
      "processed 445000 examples\n",
      "processed 446000 examples\n",
      "processed 447000 examples\n",
      "processed 448000 examples\n",
      "processed 449000 examples\n",
      "processed 450000 examples\n",
      "processed 451000 examples\n",
      "processed 452000 examples\n",
      "processed 453000 examples\n",
      "processed 454000 examples\n",
      "processed 455000 examples\n",
      "processed 456000 examples\n",
      "processed 457000 examples\n",
      "processed 458000 examples\n",
      "processed 459000 examples\n",
      "processed 460000 examples\n",
      "processed 461000 examples\n",
      "processed 462000 examples\n",
      "processed 463000 examples\n",
      "processed 464000 examples\n",
      "processed 465000 examples\n",
      "processed 466000 examples\n",
      "processed 467000 examples\n",
      "processed 468000 examples\n",
      "processed 469000 examples\n",
      "processed 470000 examples\n",
      "processed 471000 examples\n",
      "processed 472000 examples\n",
      "processed 473000 examples\n",
      "processed 474000 examples\n",
      "processed 475000 examples\n",
      "processed 476000 examples\n",
      "processed 477000 examples\n",
      "processed 478000 examples\n",
      "processed 479000 examples\n",
      "processed 480000 examples\n",
      "processed 481000 examples\n",
      "processed 482000 examples\n",
      "processed 483000 examples\n",
      "processed 484000 examples\n",
      "processed 485000 examples\n",
      "processed 486000 examples\n",
      "processed 487000 examples\n",
      "processed 488000 examples\n",
      "processed 489000 examples\n",
      "processed 490000 examples\n",
      "processed 491000 examples\n",
      "processed 492000 examples\n",
      "processed 493000 examples\n",
      "processed 494000 examples\n",
      "processed 495000 examples\n",
      "processed 496000 examples\n",
      "processed 497000 examples\n",
      "processed 498000 examples\n",
      "processed 499000 examples\n",
      "processed 500000 examples\n",
      "processed 501000 examples\n",
      "processed 502000 examples\n",
      "processed 503000 examples\n",
      "processed 504000 examples\n",
      "processed 505000 examples\n",
      "processed 506000 examples\n",
      "processed 507000 examples\n",
      "processed 508000 examples\n",
      "processed 509000 examples\n",
      "processed 510000 examples\n",
      "processed 511000 examples\n",
      "processed 512000 examples\n",
      "processed 513000 examples\n",
      "processed 514000 examples\n",
      "processed 515000 examples\n",
      "processed 516000 examples\n",
      "processed 517000 examples\n",
      "processed 518000 examples\n",
      "processed 519000 examples\n",
      "processed 520000 examples\n",
      "processed 521000 examples\n",
      "processed 522000 examples\n",
      "processed 523000 examples\n",
      "processed 524000 examples\n",
      "processed 525000 examples\n",
      "processed 526000 examples\n",
      "processed 527000 examples\n",
      "processed 528000 examples\n",
      "processed 529000 examples\n",
      "processed 530000 examples\n",
      "processed 531000 examples\n",
      "processed 532000 examples\n",
      "processed 533000 examples\n",
      "processed 534000 examples\n",
      "processed 535000 examples\n",
      "processed 536000 examples\n",
      "processed 537000 examples\n",
      "processed 538000 examples\n",
      "processed 539000 examples\n",
      "processed 540000 examples\n",
      "processed 541000 examples\n",
      "processed 542000 examples\n",
      "processed 543000 examples\n",
      "processed 544000 examples\n",
      "processed 545000 examples\n",
      "processed 546000 examples\n",
      "processed 547000 examples\n",
      "processed 548000 examples\n",
      "processed 549000 examples\n",
      "processed 550000 examples\n",
      "processed 551000 examples\n",
      "processed 552000 examples\n",
      "processed 553000 examples\n",
      "processed 554000 examples\n",
      "processed 555000 examples\n",
      "processed 556000 examples\n",
      "processed 557000 examples\n",
      "processed 558000 examples\n",
      "processed 559000 examples\n",
      "processed 560000 examples\n",
      "processed 561000 examples\n",
      "processed 562000 examples\n",
      "processed 563000 examples\n",
      "processed 564000 examples\n",
      "processed 565000 examples\n",
      "processed 566000 examples\n",
      "processed 567000 examples\n",
      "processed 568000 examples\n",
      "processed 569000 examples\n",
      "processed 570000 examples\n",
      "processed 571000 examples\n",
      "processed 572000 examples\n",
      "processed 573000 examples\n",
      "processed 574000 examples\n",
      "processed 575000 examples\n",
      "processed 576000 examples\n",
      "processed 577000 examples\n",
      "processed 578000 examples\n",
      "processed 579000 examples\n",
      "processed 580000 examples\n",
      "processed 581000 examples\n",
      "processed 582000 examples\n",
      "processed 583000 examples\n",
      "processed 584000 examples\n",
      "processed 585000 examples\n",
      "processed 586000 examples\n",
      "processed 587000 examples\n",
      "processed 588000 examples\n",
      "processed 589000 examples\n",
      "processed 590000 examples\n",
      "processed 591000 examples\n",
      "processed 592000 examples\n",
      "processed 593000 examples\n",
      "processed 594000 examples\n",
      "processed 595000 examples\n",
      "processed 596000 examples\n",
      "processed 597000 examples\n",
      "processed 598000 examples\n",
      "processed 599000 examples\n",
      "processed 600000 examples\n",
      "processed 601000 examples\n",
      "processed 602000 examples\n",
      "processed 603000 examples\n",
      "processed 604000 examples\n",
      "processed 605000 examples\n",
      "processed 606000 examples\n",
      "processed 607000 examples\n",
      "processed 608000 examples\n",
      "processed 609000 examples\n",
      "processed 610000 examples\n",
      "processed 611000 examples\n",
      "processed 612000 examples\n",
      "processed 613000 examples\n",
      "processed 614000 examples\n",
      "processed 615000 examples\n",
      "processed 616000 examples\n",
      "processed 617000 examples\n",
      "processed 618000 examples\n",
      "processed 619000 examples\n",
      "processed 620000 examples\n",
      "processed 621000 examples\n",
      "processed 622000 examples\n",
      "processed 623000 examples\n",
      "processed 624000 examples\n",
      "processed 625000 examples\n",
      "processed 626000 examples\n",
      "processed 627000 examples\n",
      "processed 628000 examples\n",
      "processed 629000 examples\n",
      "processed 630000 examples\n",
      "processed 631000 examples\n",
      "processed 632000 examples\n",
      "processed 633000 examples\n",
      "processed 634000 examples\n",
      "processed 635000 examples\n",
      "processed 636000 examples\n",
      "processed 637000 examples\n",
      "processed 638000 examples\n",
      "processed 639000 examples\n",
      "processed 640000 examples\n",
      "processed 641000 examples\n",
      "processed 642000 examples\n",
      "processed 643000 examples\n",
      "processed 644000 examples\n",
      "processed 645000 examples\n",
      "processed 646000 examples\n",
      "processed 647000 examples\n",
      "processed 648000 examples\n",
      "processed 649000 examples\n",
      "processed 650000 examples\n",
      "processed 651000 examples\n",
      "processed 652000 examples\n",
      "processed 653000 examples\n",
      "processed 654000 examples\n",
      "processed 655000 examples\n",
      "processed 656000 examples\n",
      "processed 657000 examples\n",
      "processed 658000 examples\n",
      "processed 659000 examples\n",
      "processed 660000 examples\n",
      "processed 661000 examples\n",
      "processed 662000 examples\n",
      "processed 663000 examples\n",
      "processed 664000 examples\n",
      "processed 665000 examples\n",
      "processed 666000 examples\n",
      "processed 667000 examples\n",
      "processed 668000 examples\n",
      "processed 669000 examples\n",
      "processed 670000 examples\n",
      "processed 671000 examples\n",
      "processed 672000 examples\n",
      "processed 673000 examples\n",
      "processed 674000 examples\n",
      "processed 675000 examples\n",
      "processed 676000 examples\n",
      "processed 677000 examples\n",
      "processed 678000 examples\n",
      "processed 679000 examples\n",
      "processed 680000 examples\n",
      "processed 681000 examples\n",
      "processed 682000 examples\n",
      "processed 683000 examples\n",
      "processed 684000 examples\n",
      "processed 685000 examples\n",
      "processed 686000 examples\n",
      "processed 687000 examples\n",
      "processed 688000 examples\n",
      "processed 689000 examples\n",
      "processed 690000 examples\n",
      "processed 691000 examples\n",
      "processed 692000 examples\n",
      "processed 693000 examples\n",
      "processed 694000 examples\n",
      "processed 695000 examples\n",
      "processed 696000 examples\n",
      "processed 697000 examples\n",
      "processed 698000 examples\n",
      "processed 699000 examples\n",
      "processed 700000 examples\n",
      "processed 701000 examples\n",
      "processed 702000 examples\n",
      "processed 703000 examples\n",
      "processed 704000 examples\n",
      "processed 705000 examples\n",
      "processed 706000 examples\n",
      "processed 707000 examples\n",
      "processed 708000 examples\n",
      "processed 709000 examples\n",
      "processed 710000 examples\n",
      "processed 711000 examples\n",
      "processed 712000 examples\n",
      "processed 713000 examples\n",
      "processed 714000 examples\n",
      "processed 715000 examples\n",
      "processed 716000 examples\n",
      "processed 717000 examples\n",
      "processed 718000 examples\n",
      "processed 719000 examples\n",
      "processed 720000 examples\n",
      "processed 721000 examples\n",
      "processed 722000 examples\n",
      "processed 723000 examples\n",
      "processed 724000 examples\n",
      "processed 725000 examples\n",
      "processed 726000 examples\n",
      "processed 727000 examples\n",
      "processed 728000 examples\n",
      "processed 729000 examples\n",
      "processed 730000 examples\n",
      "processed 731000 examples\n",
      "processed 732000 examples\n",
      "processed 733000 examples\n",
      "processed 734000 examples\n",
      "processed 735000 examples\n",
      "processed 736000 examples\n",
      "processed 737000 examples\n",
      "processed 738000 examples\n",
      "processed 739000 examples\n",
      "processed 740000 examples\n",
      "processed 741000 examples\n",
      "processed 742000 examples\n",
      "processed 743000 examples\n",
      "processed 744000 examples\n",
      "processed 745000 examples\n",
      "processed 746000 examples\n",
      "processed 747000 examples\n",
      "processed 748000 examples\n",
      "processed 749000 examples\n",
      "processed 750000 examples\n",
      "processed 751000 examples\n",
      "processed 752000 examples\n",
      "processed 753000 examples\n",
      "processed 754000 examples\n",
      "processed 755000 examples\n",
      "processed 756000 examples\n",
      "processed 757000 examples\n",
      "processed 758000 examples\n",
      "processed 759000 examples\n",
      "processed 760000 examples\n",
      "processed 761000 examples\n",
      "processed 762000 examples\n",
      "processed 763000 examples\n",
      "processed 764000 examples\n",
      "processed 765000 examples\n",
      "processed 766000 examples\n",
      "processed 767000 examples\n",
      "processed 768000 examples\n",
      "processed 769000 examples\n",
      "processed 770000 examples\n",
      "processed 771000 examples\n",
      "processed 772000 examples\n",
      "processed 773000 examples\n",
      "processed 774000 examples\n",
      "processed 775000 examples\n",
      "processed 776000 examples\n",
      "processed 777000 examples\n",
      "processed 778000 examples\n",
      "processed 779000 examples\n",
      "processed 780000 examples\n",
      "processed 781000 examples\n",
      "processed 782000 examples\n",
      "processed 783000 examples\n",
      "processed 784000 examples\n",
      "processed 785000 examples\n",
      "processed 786000 examples\n",
      "processed 787000 examples\n",
      "processed 788000 examples\n",
      "processed 789000 examples\n",
      "processed 790000 examples\n",
      "processed 791000 examples\n",
      "processed 792000 examples\n",
      "processed 793000 examples\n",
      "processed 794000 examples\n",
      "processed 795000 examples\n",
      "processed 796000 examples\n",
      "processed 797000 examples\n",
      "processed 798000 examples\n",
      "processed 799000 examples\n",
      "processed 800000 examples\n",
      "processed 801000 examples\n",
      "processed 802000 examples\n",
      "processed 803000 examples\n",
      "processed 804000 examples\n",
      "processed 805000 examples\n",
      "processed 806000 examples\n",
      "processed 807000 examples\n",
      "processed 808000 examples\n",
      "processed 809000 examples\n",
      "processed 810000 examples\n",
      "processed 811000 examples\n",
      "processed 812000 examples\n",
      "processed 813000 examples\n",
      "processed 814000 examples\n",
      "processed 815000 examples\n",
      "processed 816000 examples\n",
      "processed 817000 examples\n",
      "processed 818000 examples\n",
      "processed 819000 examples\n",
      "processed 820000 examples\n",
      "processed 821000 examples\n",
      "processed 822000 examples\n",
      "processed 823000 examples\n",
      "processed 824000 examples\n",
      "processed 825000 examples\n",
      "processed 826000 examples\n",
      "processed 827000 examples\n",
      "processed 828000 examples\n",
      "processed 829000 examples\n",
      "processed 830000 examples\n",
      "processed 831000 examples\n",
      "processed 832000 examples\n",
      "processed 833000 examples\n",
      "processed 834000 examples\n",
      "processed 835000 examples\n",
      "processed 836000 examples\n",
      "processed 837000 examples\n",
      "processed 838000 examples\n",
      "processed 839000 examples\n",
      "processed 840000 examples\n",
      "processed 841000 examples\n",
      "processed 842000 examples\n",
      "processed 843000 examples\n",
      "processed 844000 examples\n",
      "processed 845000 examples\n",
      "processed 846000 examples\n",
      "processed 847000 examples\n",
      "processed 848000 examples\n",
      "processed 849000 examples\n",
      "processed 850000 examples\n",
      "processed 851000 examples\n",
      "processed 852000 examples\n",
      "processed 853000 examples\n",
      "processed 854000 examples\n",
      "processed 855000 examples\n",
      "processed 856000 examples\n",
      "processed 857000 examples\n",
      "processed 858000 examples\n",
      "processed 859000 examples\n",
      "processed 860000 examples\n",
      "processed 861000 examples\n",
      "processed 862000 examples\n",
      "processed 863000 examples\n",
      "processed 864000 examples\n",
      "processed 865000 examples\n",
      "processed 866000 examples\n",
      "processed 867000 examples\n",
      "processed 868000 examples\n",
      "processed 869000 examples\n",
      "processed 870000 examples\n",
      "processed 871000 examples\n",
      "processed 872000 examples\n",
      "processed 873000 examples\n",
      "processed 874000 examples\n",
      "processed 875000 examples\n",
      "processed 876000 examples\n",
      "processed 877000 examples\n",
      "processed 878000 examples\n",
      "processed 879000 examples\n",
      "processed 880000 examples\n",
      "processed 881000 examples\n",
      "processed 882000 examples\n",
      "processed 883000 examples\n",
      "processed 884000 examples\n",
      "processed 885000 examples\n",
      "processed 886000 examples\n",
      "processed 887000 examples\n",
      "processed 888000 examples\n",
      "processed 889000 examples\n",
      "processed 890000 examples\n",
      "processed 891000 examples\n",
      "processed 892000 examples\n",
      "processed 893000 examples\n",
      "processed 894000 examples\n",
      "processed 895000 examples\n",
      "processed 896000 examples\n",
      "processed 897000 examples\n",
      "processed 898000 examples\n",
      "processed 899000 examples\n",
      "processed 900000 examples\n",
      "processed 901000 examples\n",
      "processed 902000 examples\n",
      "processed 903000 examples\n",
      "processed 904000 examples\n",
      "processed 905000 examples\n",
      "processed 906000 examples\n",
      "processed 907000 examples\n",
      "processed 908000 examples\n",
      "processed 909000 examples\n",
      "processed 910000 examples\n",
      "processed 911000 examples\n",
      "processed 912000 examples\n",
      "processed 913000 examples\n",
      "processed 914000 examples\n",
      "processed 915000 examples\n",
      "processed 916000 examples\n",
      "processed 917000 examples\n",
      "processed 918000 examples\n",
      "processed 919000 examples\n",
      "processed 920000 examples\n",
      "processed 921000 examples\n",
      "processed 922000 examples\n",
      "processed 923000 examples\n",
      "processed 924000 examples\n",
      "processed 925000 examples\n",
      "processed 926000 examples\n",
      "processed 927000 examples\n",
      "processed 928000 examples\n",
      "processed 929000 examples\n",
      "processed 930000 examples\n",
      "processed 931000 examples\n",
      "processed 932000 examples\n",
      "processed 933000 examples\n",
      "processed 934000 examples\n",
      "processed 935000 examples\n",
      "processed 936000 examples\n",
      "processed 937000 examples\n",
      "processed 938000 examples\n",
      "processed 939000 examples\n",
      "processed 940000 examples\n",
      "processed 941000 examples\n",
      "processed 942000 examples\n",
      "processed 943000 examples\n",
      "processed 944000 examples\n",
      "processed 945000 examples\n",
      "processed 946000 examples\n",
      "processed 947000 examples\n",
      "processed 948000 examples\n",
      "processed 949000 examples\n",
      "processed 950000 examples\n",
      "processed 951000 examples\n",
      "processed 952000 examples\n",
      "processed 953000 examples\n",
      "processed 954000 examples\n",
      "processed 955000 examples\n",
      "processed 956000 examples\n",
      "processed 957000 examples\n",
      "processed 958000 examples\n",
      "processed 959000 examples\n",
      "processed 960000 examples\n",
      "processed 961000 examples\n",
      "processed 962000 examples\n",
      "processed 963000 examples\n",
      "processed 964000 examples\n",
      "processed 965000 examples\n",
      "processed 966000 examples\n",
      "processed 967000 examples\n",
      "processed 968000 examples\n",
      "processed 969000 examples\n",
      "processed 970000 examples\n",
      "processed 971000 examples\n",
      "processed 972000 examples\n",
      "processed 973000 examples\n",
      "processed 974000 examples\n",
      "processed 975000 examples\n",
      "processed 976000 examples\n",
      "processed 977000 examples\n",
      "processed 978000 examples\n",
      "processed 979000 examples\n",
      "processed 980000 examples\n",
      "processed 981000 examples\n",
      "processed 982000 examples\n",
      "processed 983000 examples\n",
      "processed 984000 examples\n",
      "processed 985000 examples\n",
      "processed 986000 examples\n",
      "processed 987000 examples\n",
      "processed 988000 examples\n",
      "processed 989000 examples\n",
      "processed 990000 examples\n",
      "processed 991000 examples\n",
      "processed 992000 examples\n",
      "processed 993000 examples\n",
      "processed 994000 examples\n",
      "processed 995000 examples\n",
      "processed 996000 examples\n",
      "processed 997000 examples\n",
      "processed 998000 examples\n",
      "processed 999000 examples\n",
      "processed 1000000 examples\n",
      "processed 1001000 examples\n",
      "processed 1002000 examples\n",
      "processed 1003000 examples\n",
      "processed 1004000 examples\n",
      "processed 1005000 examples\n",
      "processed 1006000 examples\n",
      "processed 1007000 examples\n",
      "processed 1008000 examples\n",
      "processed 1009000 examples\n",
      "processed 1010000 examples\n",
      "unpickled total 1010500 examples\n",
      "saved total 202100 examples only for byte\n",
      "processed 1000 examples\n",
      "processed 2000 examples\n",
      "processed 3000 examples\n",
      "processed 4000 examples\n",
      "processed 5000 examples\n",
      "processed 6000 examples\n",
      "processed 7000 examples\n",
      "processed 8000 examples\n",
      "processed 9000 examples\n",
      "processed 10000 examples\n",
      "processed 11000 examples\n",
      "processed 12000 examples\n",
      "processed 13000 examples\n",
      "processed 14000 examples\n",
      "processed 15000 examples\n",
      "processed 16000 examples\n",
      "processed 17000 examples\n",
      "processed 18000 examples\n",
      "processed 19000 examples\n",
      "processed 20000 examples\n",
      "processed 21000 examples\n",
      "processed 22000 examples\n",
      "processed 23000 examples\n",
      "processed 24000 examples\n",
      "processed 25000 examples\n",
      "processed 26000 examples\n",
      "processed 27000 examples\n",
      "processed 28000 examples\n",
      "processed 29000 examples\n",
      "processed 30000 examples\n",
      "processed 31000 examples\n",
      "processed 32000 examples\n",
      "processed 33000 examples\n",
      "processed 34000 examples\n",
      "processed 35000 examples\n",
      "processed 36000 examples\n",
      "processed 37000 examples\n",
      "processed 38000 examples\n",
      "processed 39000 examples\n",
      "processed 40000 examples\n",
      "processed 41000 examples\n",
      "processed 42000 examples\n",
      "processed 43000 examples\n",
      "processed 44000 examples\n",
      "processed 45000 examples\n",
      "processed 46000 examples\n",
      "processed 47000 examples\n",
      "processed 48000 examples\n",
      "processed 49000 examples\n",
      "processed 50000 examples\n",
      "processed 51000 examples\n",
      "processed 52000 examples\n",
      "processed 53000 examples\n",
      "processed 54000 examples\n",
      "processed 55000 examples\n",
      "processed 56000 examples\n",
      "processed 57000 examples\n",
      "processed 58000 examples\n",
      "processed 59000 examples\n",
      "processed 60000 examples\n",
      "processed 61000 examples\n",
      "processed 62000 examples\n",
      "processed 63000 examples\n",
      "processed 64000 examples\n",
      "processed 65000 examples\n",
      "processed 66000 examples\n",
      "processed 67000 examples\n",
      "processed 68000 examples\n",
      "processed 69000 examples\n",
      "processed 70000 examples\n",
      "processed 71000 examples\n",
      "processed 72000 examples\n",
      "processed 73000 examples\n",
      "processed 74000 examples\n",
      "processed 75000 examples\n",
      "processed 76000 examples\n",
      "processed 77000 examples\n",
      "processed 78000 examples\n",
      "processed 79000 examples\n",
      "processed 80000 examples\n",
      "processed 81000 examples\n",
      "processed 82000 examples\n",
      "processed 83000 examples\n",
      "processed 84000 examples\n",
      "processed 85000 examples\n",
      "processed 86000 examples\n",
      "processed 87000 examples\n",
      "processed 88000 examples\n",
      "processed 89000 examples\n",
      "processed 90000 examples\n",
      "processed 91000 examples\n",
      "processed 92000 examples\n",
      "processed 93000 examples\n",
      "processed 94000 examples\n",
      "processed 95000 examples\n",
      "processed 96000 examples\n",
      "processed 97000 examples\n",
      "processed 98000 examples\n",
      "processed 99000 examples\n",
      "processed 100000 examples\n",
      "processed 101000 examples\n",
      "processed 102000 examples\n",
      "processed 103000 examples\n",
      "processed 104000 examples\n",
      "processed 105000 examples\n",
      "processed 106000 examples\n",
      "processed 107000 examples\n",
      "processed 108000 examples\n",
      "processed 109000 examples\n",
      "processed 110000 examples\n",
      "processed 111000 examples\n",
      "processed 112000 examples\n",
      "processed 113000 examples\n",
      "processed 114000 examples\n",
      "processed 115000 examples\n",
      "processed 116000 examples\n",
      "processed 117000 examples\n",
      "processed 118000 examples\n",
      "processed 119000 examples\n",
      "processed 120000 examples\n",
      "processed 121000 examples\n",
      "processed 122000 examples\n",
      "processed 123000 examples\n",
      "processed 124000 examples\n",
      "processed 125000 examples\n",
      "processed 126000 examples\n",
      "processed 127000 examples\n",
      "processed 128000 examples\n",
      "processed 129000 examples\n",
      "processed 130000 examples\n",
      "processed 131000 examples\n",
      "processed 132000 examples\n",
      "processed 133000 examples\n",
      "processed 134000 examples\n",
      "processed 135000 examples\n",
      "processed 136000 examples\n",
      "processed 137000 examples\n",
      "processed 138000 examples\n",
      "processed 139000 examples\n",
      "processed 140000 examples\n",
      "processed 141000 examples\n",
      "processed 142000 examples\n",
      "processed 143000 examples\n",
      "processed 144000 examples\n",
      "processed 145000 examples\n",
      "processed 146000 examples\n",
      "processed 147000 examples\n",
      "processed 148000 examples\n",
      "processed 149000 examples\n",
      "processed 150000 examples\n",
      "processed 151000 examples\n",
      "processed 152000 examples\n",
      "processed 153000 examples\n",
      "processed 154000 examples\n",
      "processed 155000 examples\n",
      "processed 156000 examples\n",
      "processed 157000 examples\n",
      "processed 158000 examples\n",
      "processed 159000 examples\n",
      "processed 160000 examples\n",
      "processed 161000 examples\n",
      "processed 162000 examples\n",
      "processed 163000 examples\n",
      "processed 164000 examples\n",
      "processed 165000 examples\n",
      "processed 166000 examples\n",
      "processed 167000 examples\n",
      "processed 168000 examples\n",
      "processed 169000 examples\n",
      "processed 170000 examples\n",
      "processed 171000 examples\n",
      "processed 172000 examples\n",
      "processed 173000 examples\n",
      "processed 174000 examples\n",
      "processed 175000 examples\n",
      "processed 176000 examples\n",
      "processed 177000 examples\n",
      "processed 178000 examples\n",
      "processed 179000 examples\n",
      "processed 180000 examples\n",
      "processed 181000 examples\n",
      "processed 182000 examples\n",
      "processed 183000 examples\n",
      "processed 184000 examples\n",
      "processed 185000 examples\n",
      "processed 186000 examples\n",
      "processed 187000 examples\n",
      "processed 188000 examples\n",
      "unpickled total 188000 examples\n",
      "saved total 37600 examples only for byte\n",
      "processed 1000 examples\n",
      "processed 2000 examples\n",
      "processed 3000 examples\n",
      "processed 4000 examples\n",
      "processed 5000 examples\n",
      "processed 6000 examples\n",
      "processed 7000 examples\n",
      "processed 8000 examples\n",
      "processed 9000 examples\n",
      "processed 10000 examples\n",
      "processed 11000 examples\n",
      "processed 12000 examples\n",
      "processed 13000 examples\n",
      "processed 14000 examples\n",
      "processed 15000 examples\n",
      "processed 16000 examples\n",
      "processed 17000 examples\n",
      "processed 18000 examples\n",
      "processed 19000 examples\n",
      "processed 20000 examples\n",
      "processed 21000 examples\n",
      "processed 22000 examples\n",
      "processed 23000 examples\n",
      "processed 24000 examples\n",
      "processed 25000 examples\n",
      "processed 26000 examples\n",
      "processed 27000 examples\n",
      "processed 28000 examples\n",
      "processed 29000 examples\n",
      "processed 30000 examples\n",
      "processed 31000 examples\n",
      "processed 32000 examples\n",
      "processed 33000 examples\n",
      "processed 34000 examples\n",
      "processed 35000 examples\n",
      "processed 36000 examples\n",
      "processed 37000 examples\n",
      "processed 38000 examples\n",
      "processed 39000 examples\n",
      "processed 40000 examples\n",
      "processed 41000 examples\n",
      "processed 42000 examples\n",
      "processed 43000 examples\n",
      "processed 44000 examples\n",
      "processed 45000 examples\n",
      "processed 46000 examples\n",
      "processed 47000 examples\n",
      "processed 48000 examples\n",
      "processed 49000 examples\n",
      "processed 50000 examples\n",
      "processed 51000 examples\n",
      "processed 52000 examples\n",
      "processed 53000 examples\n",
      "processed 54000 examples\n",
      "processed 55000 examples\n",
      "processed 56000 examples\n",
      "processed 57000 examples\n",
      "processed 58000 examples\n",
      "unpickled total 58750 examples\n",
      "saved total 11750 examples only for byte\n"
     ]
    }
   ],
   "source": [
    "# get Dataset\n",
    "data_dir = 'src/data/dataset/kor/'\n",
    "train_set = KoreanFontDataset(PickledImageProvider(data_dir+'train.obj'), vector_size=20)\n",
    "valid_set = KoreanFontDataset(PickledImageProvider(data_dir+'val.obj'), vector_size=20)\n",
    "test_set = KoreanFontDataset(PickledImageProvider(data_dir+'test.obj'), vector_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get idx samplers\n",
    "train_set_size = len(train_set)\n",
    "valid_set_size = len(valid_set)\n",
    "train_idxs = list(range(train_set_size))\n",
    "valid_idxs = list(range(valid_set_size))\n",
    "if shuffle_dataset:\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(train_idxs)\n",
    "    np.random.shuffle(valid_idxs)\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idxs)\n",
    "valid_sampler = SubsetRandomSampler(valid_idxs)\n",
    "\n",
    "# get data_loaders\n",
    "train_loader = DataLoader(train_set, \n",
    "                      batch_size=batch_size,\n",
    "                      sampler=train_sampler\n",
    "                      )\n",
    "valid_loader = DataLoader(valid_set,\n",
    "                        batch_size=batch_size,\n",
    "                        sampler=valid_sampler\n",
    "                        )\n",
    "test_loader = DataLoader(test_set,\n",
    "                        batch_size=len(test_set)\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_font_size = 128*128, img_dim=1, disc_dim = 64):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.conv1 = conv2d(img_dim, disc_dim, k_size=5, stride=2, pad=2, dilation=2, lrelu=False, bn=False)\n",
    "        self.conv2 = conv2d(disc_dim, disc_dim*2, k_size=5, stride=4, pad=2, dilation=2)\n",
    "        self.conv3 = conv2d(disc_dim*2, disc_dim*4, k_size=4, stride=4, pad=1, dilation=1)\n",
    "        self.conv4 = conv2d(disc_dim*4, disc_dim*8)\n",
    "        self.conv5 = conv2d(disc_dim*8, disc_dim*8)\n",
    "        self.fc1 = nn.Linear(disc_dim*8 , 1)\n",
    "        \n",
    "\n",
    "    def forward(self, images, batch_size):\n",
    "        batch_size = images.shape[0]\n",
    "        images = images.unsqueeze(dim=1)\n",
    "        #print(images.shape) # [8, 1, 128, 128]\n",
    "        h1 = self.conv1(images)\n",
    "        #print(h1.shape) # [8, 64, 64, 64]\n",
    "        h2 = self.conv2(h1)\n",
    "        #print(h2.shape) # [8, 128, 16, 16]\n",
    "        h3 = self.conv3(h2)\n",
    "        #print(h3.shape) # [8, 256, 4, 4]\n",
    "        h4 = self.conv4(h3)        \n",
    "        #print(h4.shape) # [8, 512, 2, 2]\n",
    "        h5 = self.conv5(h4)        \n",
    "        #print(h5.shape)\n",
    "        out = torch.sigmoid(self.fc1(h5.reshape(batch_size, -1)))\n",
    "        \n",
    "        return out.squeeze()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_dim = 148 ; gen_dim = 64\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, img_dim =1, embedded_dim = 148, conv_dim = 64):\n",
    "        super(Generator, self).__init__()\n",
    "        self.deconv1 = deconv2d(embedded_dim, conv_dim * 8, k_size=4, dilation=2, stride=2)\n",
    "        self.deconv2 = deconv2d(conv_dim * 8, conv_dim * 4, k_size=4, dilation=2, stride=2)\n",
    "        self.deconv3 = deconv2d(conv_dim * 4, conv_dim * 2, k_size=6, dilation=2, stride=4)\n",
    "        self.deconv4 = deconv2d(conv_dim * 2, conv_dim * 1, k_size=6, dilation=2, stride=4)\n",
    "        self.deconv5 = deconv2d(conv_dim * 1, img_dim, k_size=4, dilation=2, stride=2, bn=False)\n",
    "\n",
    "        \n",
    "    def forward(self, doc2vec_vector, gaussian_letter_vector, batch_size):\n",
    "        input_cat = torch.cat((doc2vec_vector, gaussian_letter_vector),dim=1)\n",
    "        embedded = input_cat.reshape([batch_size, embedded_dim, 1,1])   \n",
    "        \n",
    "        d1 = self.deconv1(embedded)\n",
    "        #print(d1.shape)\n",
    "        d2 = self.deconv2(d1)\n",
    "        #print(d2.shape)\n",
    "        d3 = self.deconv3(d2)\n",
    "        #print(d3.shape)\n",
    "        d4 = self.deconv4(d3)\n",
    "        #print(d4.shape)\n",
    "        d5 = self.deconv5(d4)\n",
    "        #print(d5.shape)\n",
    "        fake_target = d5.squeeze(dim=1)\n",
    "\n",
    "        return fake_target\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator().cuda()\n",
    "generator = Generator().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_criterion = nn.MSELoss().cuda()\n",
    "bce_criterion = nn.BCELoss().cuda()\n",
    "l1_criterion = nn.L1Loss().cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=lr)\n",
    "g_optimizer = torch.optim.Adam(generator.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_discriminator(temp_batch_size, generator, discriminator, images, \\\n",
    "                        doc2vec_Vector, gaussian_letter_vector):\n",
    "    d_optimizer.zero_grad()\n",
    "    \n",
    "    #train with the real image\n",
    "    outputs = discriminator(images, batch_size)\n",
    "    real_loss = F.binary_cross_entropy(outputs, Variable(torch.ones(batch_size)).cuda()) \n",
    "    real_score = outputs \n",
    "        \n",
    "    #train with the fake image\n",
    "    fake_images = generator(doc2vec_vector, gaussian_letter_vector, batch_size) \n",
    "    outputs = discriminator(fake_images, batch_size)    \n",
    "    fake_loss = F.binary_cross_entropy(outputs, Variable(torch.zeros(batch_size)).cuda()) \n",
    "    fake_score = outputs \n",
    "\n",
    "    d_loss = real_loss + fake_loss \n",
    "    d_loss.backward() \n",
    "    d_optimizer.step()\n",
    "    \n",
    "    return d_loss, real_score, fake_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(temp_batch_size, gaussian_letter_vector, doc2vec_vector, \\\n",
    "                    images, generator, discriminator):\n",
    "\n",
    "    g_optimizer.zero_grad()\n",
    "    \n",
    "    # Sample again for the generator and get output from discriminator\n",
    "    fake_images = generator(doc2vec_vector, gaussian_letter_vector, batch_size) \n",
    "    outputs = discriminator(fake_images, batch_size)\n",
    "\n",
    "    g_l1_loss= F.l1_loss(fake_images, images)\n",
    "    g_bce_loss = F.binary_cross_entropy(outputs, Variable(torch.ones(batch_size)).cuda())\n",
    "    \n",
    "    g_loss = g_l1_loss + g_bce_loss\n",
    "    g_loss.backward()\n",
    "    g_optimizer.step()\n",
    "    \n",
    "    return g_loss, g_l1_loss\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_discriminator(temp_batch_size, generator, discriminator, images, \\\n",
    "                        doc2vec_Vector, gaussian_letter_vector):\n",
    "    #train with the real image\n",
    "    outputs = discriminator(images, batch_size)\n",
    "    real_loss = F.binary_cross_entropy(outputs, Variable(torch.ones(batch_size)).cuda()) \n",
    "    real_score = outputs \n",
    "        \n",
    "    #train with the fake image\n",
    "    fake_images = generator(doc2vec_vector, gaussian_letter_vector, batch_size) \n",
    "    outputs = discriminator(fake_images, batch_size)    \n",
    "    fake_loss = F.binary_cross_entropy(outputs, Variable(torch.zeros(batch_size)).cuda()) \n",
    "    fake_score = outputs \n",
    "\n",
    "    d_loss = real_loss + fake_loss \n",
    "    \n",
    "    return d_loss, real_score, fake_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_generator(temp_batch_size, gaussian_letter_vector, doc2vec_vector, \\\n",
    "                    images, generator, discriminator):\n",
    "    \n",
    "    # Sample again for the generator and get output from discriminator\n",
    "    fake_images = generator(doc2vec_vector, gaussian_letter_vector, batch_size) \n",
    "    outputs = discriminator(fake_images, batch_size)\n",
    "\n",
    "    g_l1_loss= F.l1_loss(fake_images, images)\n",
    "    g_bce_loss = F.binary_cross_entropy(outputs, Variable(torch.ones(batch_size)).cuda())\n",
    "    \n",
    "    g_loss = g_l1_loss + g_bce_loss\n",
    "    \n",
    "    return g_loss, g_l1_loss\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=304)\n",
    "random_table = np.random.normal(size=[2350,128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------1 epoch----------------------------------\n",
      "Epoch [1/100], Step[1/25263], d_loss: 1.4083, g_loss: 1.9716, D(x): 0.51, D(G(z)): 0.51\n",
      "Epoch [1/100], Step[1001/25263], d_loss: 1.3998, g_loss: 1.4130, D(x): 0.50, D(G(z)): 0.50\n",
      "Epoch [1/100], Step[2001/25263], d_loss: 1.3962, g_loss: 1.2108, D(x): 0.50, D(G(z)): 0.50\n",
      "Epoch [1/100], Step[3001/25263], d_loss: 1.3941, g_loss: 1.1057, D(x): 0.50, D(G(z)): 0.50\n",
      "Epoch [1/100], Step[4001/25263], d_loss: 1.3928, g_loss: 1.0411, D(x): 0.50, D(G(z)): 0.50\n",
      "Epoch [1/100], Step[5001/25263], d_loss: 1.3919, g_loss: 0.9971, D(x): 0.50, D(G(z)): 0.50\n",
      "Epoch [1/100], Step[6001/25263], d_loss: 1.3912, g_loss: 0.9653, D(x): 0.50, D(G(z)): 0.50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-84fcad060f16>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;31m# Train the generator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         g_loss, g_l1_loss = train_generator(temp_batch_size, gaussian_letter_vector, doc2vec_vector, \\\n\u001b[1;32m---> 43\u001b[1;33m                                             images, generator, discriminator)\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0mtemp_g_total_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-27-9b66e0059071>\u001b[0m in \u001b[0;36mtrain_generator\u001b[1;34m(temp_batch_size, gaussian_letter_vector, doc2vec_vector, images, generator, discriminator)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# Sample again for the generator and get output from discriminator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mfake_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc2vec_vector\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgaussian_letter_vector\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfake_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mg_l1_loss\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ml1_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfake_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\subin2\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-daabbdb5f7a1>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, images, batch_size)\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mh2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;31m#print(h2.shape) # [8, 128, 16, 16]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mh3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[1;31m#print(h3.shape) # [8, 256, 4, 4]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mh4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\subin2\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\subin2\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\subin2\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\subin2\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m             exponential_average_factor, self.eps)\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\subin2\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   1695\u001b[0m     return torch.batch_norm(\n\u001b[0;32m   1696\u001b[0m         \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1697\u001b[1;33m         \u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1698\u001b[0m     )\n\u001b[0;32m   1699\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# set number of epochs and initialize figure counter\n",
    "num_epochs = 100\n",
    "num_batches = len(train_loader)\n",
    "num_fig = 0\n",
    "\n",
    "final_g_total_loss = []\n",
    "final_g_l1_loss = []\n",
    "final_d_loss = []\n",
    "\n",
    "final_g_total_loss_v = []\n",
    "final_g_l1_loss_v = []\n",
    "final_d_loss_v = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    temp_g_total_loss = []\n",
    "    temp_g_l1_loss = []\n",
    "    temp_d_loss = []\n",
    "    \n",
    "    temp_g_total_loss_v = []\n",
    "    temp_g_l1_loss_v = []\n",
    "    temp_d_loss_v = []\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        print('----------------------------%d epoch----------------------------------'%(epoch+1))\n",
    "    \n",
    "    for n, (vectors, font) in enumerate(train_loader):\n",
    "        doc2vec_vector = vectors['font_doc2vec']\n",
    "        letter_vector = vectors['word_index']\n",
    "        gaussian_letter_vector = random_table[letter_vector] \n",
    "\n",
    "        images = font.float().to(device)\n",
    "        doc2vec_vector = doc2vec_vector.float().to(device)\n",
    "        gaussian_letter_vector = torch.from_numpy(gaussian_letter_vector).float().to(device)\n",
    "        temp_batch_size = letter_vector.size()[0]\n",
    "    \n",
    "        # Train the discriminator\n",
    "        d_loss, real_score, fake_score =train_discriminator(temp_batch_size, generator, discriminator, \\\n",
    "                                                            images, doc2vec_vector, gaussian_letter_vector)\n",
    "       \n",
    "        \n",
    "        # Train the generator\n",
    "        g_loss, g_l1_loss = train_generator(temp_batch_size, gaussian_letter_vector, doc2vec_vector, \\\n",
    "                                            images, generator, discriminator)\n",
    "                 \n",
    "        temp_g_total_loss.append(g_loss.item())\n",
    "        temp_g_l1_loss.append(g_l1_loss.item())\n",
    "        temp_d_loss.append(d_loss.item())\n",
    "        \n",
    "\n",
    "        if n % 1000 == 0:\n",
    "            final_g_total_loss.append(np.mean(temp_g_total_loss))\n",
    "            final_g_l1_loss.append(np.mean(temp_g_l1_loss))\n",
    "            final_d_loss.append(np.mean(temp_d_loss))       \n",
    "\n",
    "            print('Epoch [%d/%d], Step[%d/%d], d_loss: %.4f, g_loss: %.4f, ' \n",
    "                  'D(x): %.2f, D(G(z)): %.2f' \n",
    "                  %(epoch + 1, num_epochs, n+1, num_batches, np.mean(final_d_loss),np.mean(final_g_total_loss),\n",
    "                    real_score.data.mean(), fake_score.data.mean()))\n",
    "        \n",
    "    # validation part\n",
    "    for n, (vectors, font) in enumerate(valid_loader):\n",
    "        \n",
    "        doc2vec_vector = vectors['font_doc2vec']\n",
    "        letter_vector = vectors['word_index']\n",
    "        gaussian_letter_vector = random_table[letter_vector] \n",
    "\n",
    "        images = font.float().to(device)\n",
    "        doc2vec_vector = doc2vec_vector.float().to(device)\n",
    "        gaussian_letter_vector = torch.from_numpy(gaussian_letter_vector).float().to(device)\n",
    "        temp_batch_size = letter_vector.size()[0]\n",
    "        \n",
    "        # Train the discriminator\n",
    "        d_loss, real_score, fake_score =valid_discriminator(temp_batch_size, generator, discriminator, \\\n",
    "                                                            images, doc2vec_vector, gaussian_letter_vector)\n",
    "       \n",
    "        \n",
    "        # Train the generator\n",
    "        g_loss, g_l1_loss = valid_generator(temp_batch_size, gaussian_letter_vector, doc2vec_vector, \\\n",
    "                                            images, generator, discriminator)\n",
    "        \n",
    "        temp_g_total_loss_v.append(g_loss.item())\n",
    "        temp_g_l1_loss_v.append(g_l1_loss.item())\n",
    "        temp_d_loss_v.append(d_loss.item())\n",
    "\n",
    "\n",
    "\n",
    "        if n % 1000 == 0:\n",
    "\n",
    "            final_g_total_loss_v.append(np.mean(temp_g_total_loss_v))\n",
    "            final_g_l1_loss_v.append(np.mean(temp_g_l1_loss_v))\n",
    "            final_d_loss_v.append(np.mean(temp_d_loss_v))       \n",
    "\n",
    "            print('Epoch [%d/%d], Step[%d/%d], valid_d_loss: %.4f, valid_g_loss: %.4f, ' \n",
    "                  'D(x): %.2f, D(G(z)): %.2f' \n",
    "                  %(epoch + 1, num_epochs, n+1, num_batches, np.mean(final_d_loss_v),np.mean(final_g_total_loss_v),\n",
    "                    real_score.data.mean(), fake_score.data.mean()))\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(final_g_total_loss)\n",
    "plt.plot(final_g_l1_loss)\n",
    "plt.plot(final_g_l1_loss_v)\n",
    "#plt.plot(final_d_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "savePath = \"D:/ 2019/generator_1210.pth\"\n",
    "torch.save(generator.state_dict(), savePath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "savePath = \"D:/ 2019/discriminator_1210.pth\"\n",
    "torch.save(discriminator.state_dict(), savePath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "#new_model = TestModel()\n",
    "#new_model.load_state_dict(torch.load(\"./output/test_model.pth\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (vectors, font) in enumerate(test_loader):\n",
    "\n",
    "    doc2vec_vector = vectors['font_doc2vec']\n",
    "    letter_vector = vectors['word_index']\n",
    "\n",
    "    images, letter_vector = font.float().to(device), letter_vector.float().to(device)\n",
    "    doc2vec_vector = doc2vec_vector.float().to(device)\n",
    "\n",
    "    temp_batch_size = letter_vector.size()[0]\n",
    "\n",
    "    fake_images = generator(images, doc2vec_vector, letter_vector, temp_batch_size) \n",
    "    if i ==0: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_images_view = fake_images.view(fake_images.size(0), 128, 128)\n",
    "images_view = images.view(images.size(0), 128, 128)\n",
    "\n",
    "plt.figure(figsize=(10, 200))\n",
    "for i in range(8):\n",
    "    plt.subplot(50, 4, i*2+1)\n",
    "    plt.imshow(images_view[i].cpu().detach().numpy())\n",
    "    plt.subplot(50, 4, (i+1)*2)\n",
    "    plt.imshow(fake_images_view[i].cpu().detach().numpy())\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:subin2]",
   "language": "python",
   "name": "conda-env-subin2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
